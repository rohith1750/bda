# Example command to start the process
start-all.sh

do nothing and create input file

sudo gedit input.txt
password :hdoop

copy the input and paste in it

sudo gedit mapper.py
sudo gedit reducer.py
copy and paste them

to run in local
cat input.txt | python3 mapper.py
cat input.txt | python3 mapper.py | sort | python3 reducer.py

now to send it to hadoop
hdfs dfs -mkdir /rohith
hdfs dfs -put input.txt /rohith/


now to run the jar command

hadoop jar '/home/hdoop/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar' -file mapper.py -mapper mapper.py -file reducer.py -reducer reducer.py -input /rohith/input.txt -output /rohith/oup1

output will be stored in oup1 to get it 
open localhost:9000
open go to rohith and get path of oup1 
cat (path of oup1)
